[INFO] Training Reward Predictor on device: cuda
[INFO] Training with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Number of iterations: 1000
        - Shapes per trajectory: 2
        - Batch size: 64
[100/1000] Loss: 0.06428593397140503
[200/1000] Loss: 0.052855104207992554
[300/1000] Loss: 0.054098524153232574
[400/1000] Loss: 0.04389194771647453
Intermediate model save at reward_induced/models/encoder/encoder_dist0_400.pt
[500/1000] Loss: 0.024699712172150612
[600/1000] Loss: 0.0174719225615263
[700/1000] Loss: 0.013065746985375881
[800/1000] Loss: 0.010908544063568115
Intermediate model save at reward_induced/models/encoder/encoder_dist0_800.pt
[900/1000] Loss: 0.006964921951293945
[1000/1000] Loss: 0.005332275293767452
Loss plot saved at reward_induced/logs/encoder_dist0.png
Final model saved at reward_induced/models/encoder/encoder_dist0_final.pt
Training complete.
