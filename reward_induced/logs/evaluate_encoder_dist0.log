[INFO] Loaded Reward Predictor from reward_induced/models/encoder/encoder_dist0_final.pt
[INFO] Evaluating Reward Predictor with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Shapes per trajectory: 2
        - Batch size: 128
        - Model loaded from: reward_induced/models/encoder/encoder_dist0_final.pt
True rewards from 0th traj: tensor([[0.7530, 0.7318, 0.7105, 0.6893, 0.6681, 0.6469, 0.6256, 0.6044, 0.5832,
         0.5620, 0.5407, 0.5195, 0.4983, 0.4770, 0.4558, 0.4346, 0.4134, 0.3921,
         0.3709, 0.3497, 0.3285, 0.3072, 0.2860, 0.2648, 0.2436, 0.2223, 0.2011,
         0.1799, 0.1587],
        [0.2965, 0.3164, 0.3363, 0.3562, 0.3761, 0.3960, 0.4159, 0.4358, 0.4557,
         0.4756, 0.4955, 0.5154, 0.5353, 0.5552, 0.5751, 0.5950, 0.6149, 0.6348,
         0.6547, 0.6746, 0.6945, 0.7144, 0.7343, 0.7542, 0.7741, 0.7940, 0.8139,
         0.8338, 0.8537],
        [0.6217, 0.6079, 0.5941, 0.5803, 0.5665, 0.5527, 0.5389, 0.5251, 0.5113,
         0.4976, 0.4838, 0.4700, 0.4562, 0.4424, 0.4286, 0.4148, 0.4010, 0.3872,
         0.3734, 0.3596, 0.3458, 0.3320, 0.3183, 0.3045, 0.2907, 0.2769, 0.2631,
         0.2493, 0.2355],
        [0.4421, 0.4374, 0.4327, 0.4279, 0.4232, 0.4185, 0.4138, 0.4091, 0.4043,
         0.3996, 0.3949, 0.3902, 0.3854, 0.3807, 0.3760, 0.3713, 0.3665, 0.3618,
         0.3571, 0.3524, 0.3476, 0.3429, 0.3382, 0.3335, 0.3288, 0.3240, 0.3193,
         0.3146, 0.3099]], device='cuda:0')
Predicted rewards from 0th traj: tensor([[0.6663, 0.6381, 0.6432, 0.6214, 0.6098, 0.5926, 0.5833, 0.5820, 0.5771,
         0.5240, 0.4686, 0.4505, 0.5292, 0.4700, 0.4164, 0.3684, 0.3702, 0.3734,
         0.3642, 0.3519, 0.3393, 0.3168, 0.2918, 0.2906, 0.2730, 0.2645, 0.2472,
         0.2330, 0.2197],
        [0.3501, 0.3624, 0.3763, 0.3832, 0.3869, 0.4024, 0.4020, 0.3891, 0.3924,
         0.4043, 0.4262, 0.4623, 0.4365, 0.4793, 0.4802, 0.5355, 0.5322, 0.5642,
         0.5613, 0.5716, 0.5706, 0.6436, 0.6870, 0.7182, 0.7566, 0.7477, 0.7716,
         0.7590, 0.7544],
        [0.7373, 0.6841, 0.6771, 0.6461, 0.6252, 0.6224, 0.6103, 0.6003, 0.5866,
         0.5827, 0.5861, 0.5422, 0.4638, 0.4581, 0.4628, 0.4585, 0.4320, 0.4183,
         0.4053, 0.3942, 0.3794, 0.3652, 0.3457, 0.3462, 0.3279, 0.3144, 0.2747,
         0.2305, 0.1991],
        [0.3813, 0.4371, 0.4437, 0.4400, 0.4368, 0.4360, 0.4314, 0.4312, 0.4283,
         0.4201, 0.4089, 0.3808, 0.4062, 0.4007, 0.4012, 0.4105, 0.4087, 0.3936,
         0.3872, 0.3859, 0.3869, 0.3751, 0.3726, 0.3673, 0.3595, 0.3344, 0.3260,
         0.3211, 0.3050]], device='cuda:0')
Losses:
        - AgentXReward:  0.002307176124304533
        - AgentYReward:  0.004463225603103638
        - TargetXReward: 0.0032726910430938005
        - TargetYReward: 0.0007051193388178945
Evaluation complete.
