[INFO] Loaded Reward Predictor from reward_induced/models/encoder/encoder_dist0_final.pt
[INFO] Evaluating Reward Predictor with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Shapes per trajectory: 2
        - Batch size: 128
        - Model loaded from: reward_induced/models/encoder/encoder_dist0_final.pt
True rewards from 0th traj: tensor([[0.7024, 0.7304, 0.7584, 0.7865, 0.8145, 0.8425, 0.8705, 0.8985, 0.8735,
         0.8455, 0.8175, 0.7894, 0.7614, 0.7334, 0.7054, 0.6774, 0.6494, 0.6214,
         0.5934, 0.5654, 0.5373, 0.5093, 0.4813, 0.4533, 0.4253, 0.3973, 0.3693,
         0.3413, 0.3132],
        [0.4556, 0.4548, 0.4540, 0.4532, 0.4524, 0.4516, 0.4509, 0.4501, 0.4493,
         0.4485, 0.4477, 0.4470, 0.4462, 0.4454, 0.4446, 0.4438, 0.4430, 0.4423,
         0.4415, 0.4407, 0.4399, 0.4391, 0.4384, 0.4376, 0.4368, 0.4360, 0.4352,
         0.4344, 0.4337],
        [0.4241, 0.4301, 0.4360, 0.4420, 0.4479, 0.4539, 0.4598, 0.4658, 0.4717,
         0.4777, 0.4836, 0.4896, 0.4955, 0.5015, 0.5074, 0.5134, 0.5193, 0.5253,
         0.5312, 0.5372, 0.5431, 0.5491, 0.5550, 0.5610, 0.5669, 0.5729, 0.5788,
         0.5848, 0.5907],
        [0.8997, 0.8920, 0.8837, 0.8755, 0.8672, 0.8590, 0.8507, 0.8424, 0.8342,
         0.8259, 0.8177, 0.8094, 0.8011, 0.7929, 0.7846, 0.7764, 0.7681, 0.7598,
         0.7516, 0.7433, 0.7351, 0.7268, 0.7185, 0.7103, 0.7020, 0.6938, 0.6855,
         0.6772, 0.6690]], device='cuda:0')
Predicted rewards from 0th traj: tensor([[0.5999, 0.7296, 0.8143, 0.8944, 0.9043, 0.9524, 0.9291, 0.9087, 0.8978,
         0.7801, 0.6075, 0.6029, 0.5260, 0.6394, 0.5831, 0.5906, 0.5946, 0.5869,
         0.5888, 0.5883, 0.5820, 0.5871, 0.5833, 0.5710, 0.5029, 0.4527, 0.4163,
         0.3930, 0.3375],
        [0.4082, 0.4240, 0.3857, 0.3789, 0.3789, 0.4007, 0.3813, 0.3849, 0.4543,
         0.4349, 0.4448, 0.4275, 0.5195, 0.4864, 0.5432, 0.4829, 0.4264, 0.4378,
         0.4188, 0.3428, 0.3288, 0.3054, 0.3049, 0.3210, 0.3172, 0.3532, 0.3476,
         0.3775, 0.3629],
        [0.5039, 0.4008, 0.3947, 0.3847, 0.3748, 0.4041, 0.3869, 0.3732, 0.4109,
         0.5292, 0.7137, 0.7543, 0.7504, 0.7132, 0.6779, 0.6315, 0.5880, 0.5742,
         0.5649, 0.5566, 0.5425, 0.5523, 0.5469, 0.5451, 0.5719, 0.5531, 0.5886,
         0.5799, 0.6248],
        [0.8060, 0.8137, 0.8106, 0.8047, 0.8081, 0.7739, 0.8067, 0.8098, 0.8066,
         0.7988, 0.7992, 0.7927, 0.7943, 0.7995, 0.7946, 0.7939, 0.7274, 0.7305,
         0.6735, 0.7220, 0.6777, 0.7091, 0.6828, 0.6683, 0.6380, 0.6176, 0.6180,
         0.6132, 0.6142]], device='cuda:0')
Losses:
        - AgentXReward:  0.008162685669958591
        - AgentYReward:  0.008057327009737492
        - TargetXReward: 0.003631031606346369
        - TargetYReward: 0.0034653476905077696
Evaluation complete.
