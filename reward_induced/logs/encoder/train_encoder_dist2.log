[INFO] Training Reward Predictor on device: cuda
[INFO] Training with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Number of iterations: 1500
        - Shapes per trajectory: 4
        - Batch size: 64
[100/1500] Loss: 0.055048711597919464
[200/1500] Loss: 0.052490174770355225
[300/1500] Loss: 0.040752753615379333
[400/1500] Loss: 0.029415160417556763
Intermediate model save at reward_induced/models/encoder/encoder_dist2_400.pt
[500/1500] Loss: 0.026893166825175285
[600/1500] Loss: 0.02810668759047985
[700/1500] Loss: 0.027396757155656815
[800/1500] Loss: 0.024709666147828102
Intermediate model save at reward_induced/models/encoder/encoder_dist2_800.pt
[900/1500] Loss: 0.023205645382404327
[1000/1500] Loss: 0.02111855521798134
[1100/1500] Loss: 0.020949693396687508
[1200/1500] Loss: 0.018983209505677223
Intermediate model save at reward_induced/models/encoder/encoder_dist2_1200.pt
[1300/1500] Loss: 0.017190007492899895
[1400/1500] Loss: 0.011303066276013851
[1500/1500] Loss: 0.007007236126810312
Loss plot saved at reward_induced/logs/encoder/encoder_dist2.png
Final model saved at reward_induced/models/encoder/encoder_dist2_final.pt
Training complete.
