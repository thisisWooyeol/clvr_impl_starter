[INFO] Loaded Reward Predictor from reward_induced/models/encoder/encoder_dist2_final.pt
[INFO] Evaluating Reward Predictor with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Shapes per trajectory: 4
        - Batch size: 128
        - Model loaded from: reward_induced/models/encoder/encoder_dist2_final.pt
True rewards from 0th traj: tensor([[0.8029, 0.7654, 0.7278, 0.6903, 0.6527, 0.6152, 0.5776, 0.5400, 0.5025,
         0.4649, 0.4274, 0.3898, 0.3523, 0.3147, 0.2771, 0.2396, 0.2020, 0.1645,
         0.1269, 0.1106, 0.1482, 0.1858, 0.2233, 0.2609, 0.2984, 0.3360, 0.3735,
         0.4111, 0.4487],
        [0.7546, 0.8037, 0.8528, 0.8981, 0.8490, 0.7999, 0.7508, 0.7017, 0.6526,
         0.6035, 0.5544, 0.5053, 0.4562, 0.4071, 0.3580, 0.3089, 0.2598, 0.2107,
         0.1616, 0.1124, 0.1367, 0.1858, 0.2349, 0.2840, 0.3331, 0.3822, 0.4313,
         0.4804, 0.5295],
        [0.8534, 0.8972, 0.8590, 0.8152, 0.7714, 0.7277, 0.6839, 0.6401, 0.5963,
         0.5525, 0.5087, 0.4649, 0.4211, 0.3773, 0.3336, 0.2898, 0.2460, 0.2022,
         0.1584, 0.1146, 0.1292, 0.1730, 0.2167, 0.2605, 0.3043, 0.3481, 0.3919,
         0.4357, 0.4795],
        [0.8027, 0.8194, 0.8362, 0.8529, 0.8697, 0.8865, 0.8968, 0.8800, 0.8633,
         0.8465, 0.8298, 0.8130, 0.7963, 0.7795, 0.7628, 0.7460, 0.7292, 0.7125,
         0.6957, 0.6790, 0.6622, 0.6455, 0.6287, 0.6120, 0.5952, 0.5784, 0.5617,
         0.5449, 0.5282]], device='cuda:0')
Predicted rewards from 0th traj: tensor([[0.7625, 0.6937, 0.6661, 0.6955, 0.6222, 0.6411, 0.6206, 0.5879, 0.5510,
         0.5293, 0.4885, 0.4196, 0.3119, 0.2530, 0.2459, 0.2237, 0.2729, 0.2122,
         0.2183, 0.1930, 0.1635, 0.1698, 0.1616, 0.1922, 0.2199, 0.2437, 0.3134,
         0.3412, 0.4548],
        [0.6963, 0.7052, 0.7300, 0.7212, 0.7304, 0.7162, 0.7333, 0.7281, 0.6726,
         0.6540, 0.6756, 0.5490, 0.4842, 0.4232, 0.4612, 0.3879, 0.4537, 0.4258,
         0.4170, 0.2528, 0.1753, 0.1545, 0.1677, 0.2644, 0.3231, 0.3423, 0.3607,
         0.4757, 0.6014],
        [0.8027, 0.8428, 0.8654, 0.8446, 0.8146, 0.7741, 0.7240, 0.6635, 0.6047,
         0.5746, 0.5249, 0.4843, 0.4652, 0.4075, 0.3521, 0.3053, 0.2104, 0.2038,
         0.1490, 0.1618, 0.1538, 0.1379, 0.1634, 0.2438, 0.2737, 0.3251, 0.3574,
         0.4007, 0.4332],
        [0.7809, 0.7874, 0.8194, 0.8549, 0.8406, 0.8517, 0.8492, 0.8448, 0.8486,
         0.8291, 0.8070, 0.8212, 0.8008, 0.7538, 0.7464, 0.7268, 0.5925, 0.5372,
         0.6727, 0.6923, 0.6760, 0.6550, 0.6415, 0.6398, 0.6042, 0.5904, 0.5811,
         0.5302, 0.5293]], device='cuda:0')
Losses:
        - AgentXReward:  0.006669142749160528
        - AgentYReward:  0.007044503465294838
        - TargetXReward: 0.0010912115685641766
        - TargetYReward: 0.0011004001135006547
Evaluation complete.
