[INFO] Loaded Reward Predictor from reward_induced/models/encoder/encoder_dist1_final.pt
[INFO] Evaluating Reward Predictor with the following configuration:
        - Input shape: (3,64,64)
        - Number of frames: 1
        - Number of future frames: 29
        - Reward types: ['agent_x', 'agent_y', 'target_x', 'target_y']
        - Shapes per trajectory: 3
        - Batch size: 128
        - Model loaded from: reward_induced/models/encoder/encoder_dist1_final.pt
True rewards from 0th traj: tensor([[0.3091, 0.2890, 0.2690, 0.2490, 0.2289, 0.2089, 0.1889, 0.1688, 0.1488,
         0.1288, 0.1088, 0.1113, 0.1313, 0.1513, 0.1714, 0.1914, 0.2114, 0.2315,
         0.2515, 0.2715, 0.2916, 0.3116, 0.3316, 0.3517, 0.3717, 0.3917, 0.4118,
         0.4318, 0.4518],
        [0.3174, 0.3622, 0.4070, 0.4518, 0.4966, 0.5415, 0.5863, 0.6311, 0.6759,
         0.7207, 0.7656, 0.8104, 0.8552, 0.9000, 0.8552, 0.8104, 0.7655, 0.7207,
         0.6759, 0.6311, 0.5863, 0.5414, 0.4966, 0.4518, 0.4070, 0.3622, 0.3173,
         0.2725, 0.2277],
        [0.3055, 0.2943, 0.2830, 0.2718, 0.2605, 0.2493, 0.2381, 0.2268, 0.2156,
         0.2043, 0.1931, 0.1819, 0.1706, 0.1594, 0.1481, 0.1369, 0.1257, 0.1144,
         0.1032, 0.1081, 0.1193, 0.1305, 0.1418, 0.1530, 0.1643, 0.1755, 0.1868,
         0.1980, 0.2092],
        [0.6458, 0.6032, 0.5606, 0.5180, 0.4754, 0.4328, 0.3901, 0.3475, 0.3049,
         0.2623, 0.2197, 0.1771, 0.1345, 0.1081, 0.1507, 0.1933, 0.2359, 0.2786,
         0.3212, 0.3638, 0.4064, 0.4490, 0.4916, 0.5342, 0.5768, 0.6194, 0.6620,
         0.7046, 0.7472]], device='cuda:0')
Predicted rewards from 0th traj: tensor([[0.3101, 0.2650, 0.2615, 0.2561, 0.3290, 0.3090, 0.2209, 0.1937, 0.1779,
         0.1799, 0.1825, 0.1741, 0.2118, 0.1758, 0.1906, 0.1580, 0.1898, 0.1499,
         0.1876, 0.2100, 0.2141, 0.1623, 0.1724, 0.2966, 0.3330, 0.3005, 0.3243,
         0.3562, 0.4395],
        [0.2920, 0.3112, 0.3282, 0.4053, 0.5519, 0.5482, 0.4862, 0.6296, 0.6204,
         0.7000, 0.6803, 0.7770, 0.6998, 0.7189, 0.7750, 0.7831, 0.8060, 0.8368,
         0.7842, 0.7362, 0.7239, 0.5211, 0.5094, 0.5337, 0.4279, 0.3955, 0.2591,
         0.2519, 0.2518],
        [0.2951, 0.3072, 0.3025, 0.2910, 0.2842, 0.2701, 0.2279, 0.2298, 0.2184,
         0.1954, 0.1869, 0.1934, 0.1830, 0.1838, 0.1911, 0.1773, 0.1586, 0.1635,
         0.1682, 0.1734, 0.1571, 0.1568, 0.1503, 0.1666, 0.1935, 0.2019, 0.2113,
         0.2081, 0.2102],
        [0.7136, 0.6255, 0.5936, 0.5555, 0.4813, 0.4622, 0.4434, 0.3803, 0.3418,
         0.2746, 0.2261, 0.2045, 0.1426, 0.1220, 0.1274, 0.1573, 0.1886, 0.2467,
         0.2878, 0.3424, 0.4106, 0.4214, 0.4643, 0.5284, 0.5670, 0.5961, 0.6503,
         0.7058, 0.7359]], device='cuda:0')
Losses:
        - AgentXReward:  0.005146558862179518
        - AgentYReward:  0.005022016353905201
        - TargetXReward: 0.0010184920392930508
        - TargetYReward: 0.0010783826000988483
Evaluation complete.
